{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites to run different code snippets below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from scipy import signal\n",
    "import xarray as xr\n",
    "import pylab\n",
    "import operator\n",
    "import pickle as pkl\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# generate a dictionary {station_id -> formatted_staion_name}\n",
    "def get_station_dict():\n",
    "    observation_data = nc.Dataset(observations)\n",
    "    station_name_dict = {}\n",
    "    for i in range(observation_data['station'].size):\n",
    "        try:\n",
    "            name = b''.join(list(observation_data['name'][i].compressed())).decode('utf-8')\n",
    "        except AttributeError:\n",
    "            name = b''.join(list(observation_data['name'][i])).decode('utf-8')\n",
    "        station_name_dict[i] = name\n",
    "    return station_name_dict\n",
    "\n",
    "# plot the map of switzerland as background image\n",
    "def plot_map(ax, rlat_min, rlat_max, rlon_min, rlon_max):\n",
    "    dd = xr.open_dataset(data_path + \"/c1ffsurf000_timeinvariant_lonlat.nc\")\n",
    "    dd.set_coords([\"rlon\", \"rlat\"], inplace=True)\n",
    "    swiss_data = dd.sel(rlon=slice(rlon_min, rlon_max), rlat=slice(rlat_min, rlat_max))\n",
    "    swiss_data.FR_LAND.isel(time = 0).plot.pcolormesh(\"rlon\", \"rlat\", alpha=0.8, cmap=plt.cm.get_cmap('GnBu_r'), add_colorbar=False)\n",
    "    swiss_data.HH.isel(time = 0).plot.pcolormesh(\"rlon\", \"rlat\", alpha=0.6, cmap=plt.cm.get_cmap('YlGn'), add_colorbar=False)\n",
    "\n",
    "# get time axis for plot\n",
    "def get_time_axis(data_length, year_length):\n",
    "    start=datetime.strptime('15100100', '%y%m%d%H')\n",
    "    x_times = [start + timedelta(hours=t*3) for t in range(data_length)]\n",
    "    return [x_times[i:i + year_length] for i in range(0, data_length, year_length)]\n",
    "\n",
    "# filter out all corrupted measurements\n",
    "def get_filtered_data(x,data):\n",
    "    if len(x) != len(data):\n",
    "        raise Exception('Timedate array and data do not have the same length!')\n",
    "    return zip(*[(x_,d) for x_,d in zip(x,data) if d < 1e10])\n",
    "\n",
    "# paths for data and plots\n",
    "grid_size = 9\n",
    "data_path = '/home/n1no/Documents/ethz/master_thesis/code/project/data'\n",
    "experiment_data_path = data_path + '/preprocessed_data/grid_size_%s' % grid_size\n",
    "error_data_path = experiment_data_path + '/baseline_station_error.nc'\n",
    "time_invariant_data_per_station_path = experiment_data_path + '/time_invariant_data_per_station.pkl'\n",
    "plot_output_path = '/home/n1no/Documents/ethz/master_thesis/code/project/results/nearest_grid_point_baseline/all_lead_times'\n",
    "plot_output_path_no_lead_times = '/home/n1no/Documents/ethz/master_thesis/code/project/results/nearest_grid_point_baseline/no_lead_times'\n",
    "observations = data_path + '/observations/meteoswiss_t2m_20151001-20171114.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coordinates:\n",
       "  * station        (station) int64 2 3 4 6 7 8 9 10 11 13 14 15 17 18 19 20 ...\n",
       "  * init_datetime  (init_datetime) float64 1.446e+18 1.449e+18 1.452e+18 ...\n",
       "  * lead           (lead) int64 0 4 8 12 16 20 24 28 32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Error for each Station plotted per Lead Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete error of nearest grid point baseline for lead 0: 1.524599704929745 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n1no/anaconda3/envs/python3_thesis/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete error of nearest grid point baseline for lead 1: 1.5687164835043077 K\n",
      "Complete error of nearest grid point baseline for lead 2: 1.6734138525301425 K\n",
      "Complete error of nearest grid point baseline for lead 3: 1.7951230954805293 K\n",
      "Complete error of nearest grid point baseline for lead 4: 1.8338030059496346 K\n",
      "Complete error of nearest grid point baseline for lead 5: 1.8159432719331556 K\n",
      "Complete error of nearest grid point baseline for lead 6: 1.8469758590503835 K\n",
      "Complete error of nearest grid point baseline for lead 7: 1.9230893156200652 K\n",
      "Complete error of nearest grid point baseline for lead 8: 1.9018908942599277 K\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot mean error per station with variance, if invalid errors are excluded (v.2.0)\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "error_data_array = xr.open_dataarray(error_data_path)\n",
    "num_stations, num_predictions, num_future_predictions = error_data_array.shape\n",
    "error_data = error_data_array.data\n",
    "\n",
    "for lead_time in range(num_future_predictions):\n",
    "    print('Complete error of nearest grid point baseline for lead %s: %s K'\n",
    "          % (lead_time, np.mean([abs(e) for e in error_data[:,:,lead_time].flatten() if np.abs(e) < 1e10])))\n",
    "    N = num_stations\n",
    "    station_error_means, station_error_std = np.zeros(num_stations), np.zeros(num_stations)\n",
    "    for i in range(num_stations):\n",
    "        valid_errors = [e for e in error_data[i,:,lead_time] if np.abs(e) < 1e10]\n",
    "        station_error_means[i] = np.mean(valid_errors)\n",
    "        station_error_std[i] = np.std(valid_errors)\n",
    "\n",
    "    width = 0.35\n",
    "    split = int(N/3)\n",
    "    ind = np.arange(split)  # the x locations for the groups\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, sharey=True, figsize=(20, 10))\n",
    "    for i in range(3):\n",
    "        axes[i].bar(ind, station_error_means[ind+i*split], width,align='center', color='r', yerr=station_error_std[ind+i*split])\n",
    "        axes[i].set_xlim(-width,split)\n",
    "        axes[i].set_xticks(ind)\n",
    "        axes[i].set_xticklabels(['S' + str(idx+i*split) for idx in ind])\n",
    "        axes[i].grid('On')\n",
    "\n",
    "    # add some text for labels, title and axes ticks\n",
    "    plt.ylim((-5,7))\n",
    "    plt.yticks(range(-5,7))\n",
    "    axes[1].set_ylabel('Error [K]')\n",
    "    axes[0].set_title('Mean Temperature Error for each Station over compelte Data for lead %s' % (lead_time if lead_time == 0 else \"+%s\" % lead_time))\n",
    "    fig.savefig(plot_output_path + '/nearest_grid_prediction_error_per_station_lead_%s.png' % lead_time)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete error of nearest grid point baseline for lead 0: 1.524599704929745 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n1no/anaconda3/envs/python3_thesis/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete error of nearest grid point baseline for lead 1: 1.5687164835043077 K\n",
      "Complete error of nearest grid point baseline for lead 2: 1.6734138525301425 K\n",
      "Complete error of nearest grid point baseline for lead 3: 1.7951230954805293 K\n",
      "Complete error of nearest grid point baseline for lead 4: 1.8338030059496346 K\n",
      "Complete error of nearest grid point baseline for lead 5: 1.8159432719331556 K\n",
      "Complete error of nearest grid point baseline for lead 6: 1.8469758590503835 K\n",
      "Complete error of nearest grid point baseline for lead 7: 1.9230893156200652 K\n",
      "Complete error of nearest grid point baseline for lead 8: 1.9018908942599277 K\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot mean absolute error per station with variance, if invalid errors are excluded  (v.2.0)\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "error_data_array = xr.open_dataarray(error_data_path)\n",
    "num_stations, num_predictions, num_future_predictions = error_data_array.shape\n",
    "error_data = error_data_array.data\n",
    "\n",
    "for lead_time in range(num_future_predictions):\n",
    "    print('Complete error of nearest grid point baseline for lead %s: %s K'\n",
    "          % (lead_time, np.mean([abs(e) for e in error_data[:,:,lead_time].flatten() if np.abs(e) < 1e10])))\n",
    "    N = num_stations\n",
    "    station_error_means, station_error_std = np.zeros(num_stations), np.zeros(num_stations)\n",
    "    for i in range(num_stations):\n",
    "        valid_errors = [abs(e) for e in error_data[i,:,lead_time] if np.abs(e) < 1e10]\n",
    "        station_error_means[i] = np.mean(valid_errors)\n",
    "        station_error_std[i] = np.std(valid_errors)\n",
    "\n",
    "    width = 0.35\n",
    "    split = int(N/3)\n",
    "    ind = np.arange(split)  # the x locations for the groups\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, sharey=True, figsize=(20, 10))\n",
    "    for i in range(3):\n",
    "        axes[i].bar(ind, station_error_means[ind+i*split], width,align='center', color='r', yerr=station_error_std[ind+i*split])\n",
    "        axes[i].set_xlim(-width,split)\n",
    "        axes[i].set_xticks(ind)\n",
    "        axes[i].set_xticklabels(['S' + str(idx+i*split) for idx in ind])\n",
    "        axes[i].grid('On')\n",
    "\n",
    "    # add some text for labels, title and axes ticks\n",
    "    plt.ylim((0,7))\n",
    "    plt.yticks(range(7))\n",
    "    axes[1].set_ylabel('Error [K]')\n",
    "    axes[0].set_title('Mean absolute Temperature Error for each Station over compelte Data for lead %s' % (lead_time if lead_time == 0 else \"+%s\" % lead_time))\n",
    "    fig.savefig(plot_output_path + '/nearest_grid_absolute_prediction_error_per_station_lead_%s.png' % lead_time)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Error over Lead Time per Initialization Time plotted per Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot mean error by initialization time and lead time (v.2.0)\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "station_name_dict = get_station_dict()\n",
    "\n",
    "error_data_array = xr.open_dataarray(error_data_path)\n",
    "num_stations, num_predictions, num_future_predictions = error_data_array.shape\n",
    "error_data = error_data_array.data\n",
    "\n",
    "x = range(0,num_future_predictions)\n",
    "initialization_times = range(0,24,3)\n",
    "\n",
    "for station in range(num_stations):\n",
    "    \n",
    "    # plot error per station by lead\n",
    "    fig, axes = plt.subplots(len(initialization_times), sharex=True, sharey=True, figsize=(20, 20))\n",
    "    max_difference_per_station = -np.inf\n",
    "    for idx, init_time in enumerate(initialization_times):\n",
    "        error_per_init_time = []\n",
    "        for lead in range(num_future_predictions):\n",
    "            error_per_init_time += [np.mean([e for e in error_data[station,idx::8,lead].flatten() if np.abs(e) < 1e10])]\n",
    "        axes[idx].plot(x, error_per_init_time)\n",
    "        axes[idx].set_ylabel('Error [°C]')\n",
    "        axes[idx].annotate('Init. Time: %s' % init_time,  xy=(0.005, 0.85), xycoords=\"axes fraction\", fontsize=16)\n",
    "        \n",
    "        max_difference_per_init_time = (max(error_per_init_time) - min(error_per_init_time))\n",
    "        axes[idx].annotate('Max Temp. Diff.: %.2f °C' % max_difference_per_init_time,\n",
    "                   xy=(1, 0.95), horizontalalignment='right', verticalalignment='top', color='black',\n",
    "                 xycoords=\"axes fraction\", fontsize=16)\n",
    "        \n",
    "        max_difference_per_station = np.maximum(max_difference_per_station, max_difference_per_init_time)\n",
    "    plt.xticks(x, ['0h'] + ['+%sh' % i for i in x[1:]])\n",
    "    plt.xlabel('Lead Time')\n",
    "    plt.suptitle('%s - Error by Initialization & Lead Time' % station_name_dict[station], fontsize=22)\n",
    "    axes[0].annotate('Total Max Temp. Diff.: %.2f °C' % max_difference_per_station,\n",
    "                       xy=(1, 1.05), horizontalalignment='right', verticalalignment='bottom', color='red',\n",
    "                     xycoords=\"axes fraction\", fontsize=16)\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    fig.savefig(plot_output_path + '/error_by_init_time_and_lead_time/Station_%s.png' % station)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot mean absolute error by initialization time and lead time (v.2.0)\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "station_name_dict = get_station_dict()\n",
    "\n",
    "error_data_array = xr.open_dataarray(error_data_path)\n",
    "num_stations, num_predictions, num_future_predictions = error_data_array.shape\n",
    "error_data = error_data_array.data\n",
    "\n",
    "x = range(0,num_future_predictions)\n",
    "initialization_times = range(0,24,3)\n",
    "\n",
    "for station in range(num_stations):\n",
    "    \n",
    "    # plot error per station by lead\n",
    "    fig, axes = plt.subplots(len(initialization_times), sharex=True, sharey=True, figsize=(20, 20))\n",
    "    error_per_station = []\n",
    "    for idx, init_time in enumerate(initialization_times):\n",
    "        error_per_init_time = []\n",
    "        for lead in range(num_future_predictions):\n",
    "            error_per_init_time += [np.mean([abs(e) for e in error_data[station,idx::8,lead].flatten() if np.abs(e) < 1e10])]\n",
    "        axes[idx].plot(x, error_per_init_time)\n",
    "        axes[idx].set_ylabel('Error [°C]')\n",
    "        axes[idx].annotate('Init. Time: %s' % init_time,  xy=(0.005, 0.85), xycoords=\"axes fraction\", fontsize=16)\n",
    "        error_per_station += error_per_init_time\n",
    "    plt.xticks(x, ['0h'] + ['+%sh' % i for i in x[1:]])\n",
    "    plt.xlabel('Lead Time')\n",
    "    plt.suptitle('%s - Absolute Error by Initialization & Lead Time' % station_name_dict[station], fontsize=22)\n",
    "    axes[0].annotate('Total Max Temp. Diff.: %.2f °C' % max_difference_per_station,\n",
    "                       xy=(1, 1.05), horizontalalignment='right', verticalalignment='bottom', color='red',\n",
    "                     xycoords=\"axes fraction\", fontsize=16)\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    fig.savefig(plot_output_path + '/absolute_error_by_init_time_and_lead_time/Station_%s.png' % station)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Error over Lead Times (averaged over all Init. Times) plotted per Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot mean error by lead time (v.2.0)\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "station_name_dict = get_station_dict()\n",
    "\n",
    "error_data_array = xr.open_dataarray(error_data_path)\n",
    "num_stations, num_predictions, num_future_predictions = error_data_array.shape\n",
    "error_data = error_data_array.data\n",
    "\n",
    "x = range(0,num_future_predictions)\n",
    "initialization_times = range(0,24,3)\n",
    "\n",
    "# calculate the error per station and lead, and the overall min and max to scale the plots\n",
    "min_error, max_error = np.inf, -np.inf\n",
    "error = np.zeros((num_stations, num_future_predictions))\n",
    "for station in range(num_stations):\n",
    "    for lead in range(num_future_predictions):\n",
    "        error[station, lead] = np.mean([e for e in error_data[station,:,lead].flatten() if np.abs(e) < 1e10])\n",
    "        min_error = np.minimum(min_error, error[station, lead])\n",
    "        max_error = np.maximum(max_error, error[station, lead])\n",
    "\n",
    "# plot the data\n",
    "for station in range(num_stations):\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.plot(x, error[station])\n",
    "    max_diff = np.max(error[station]) - np.min(error[station])\n",
    "    plt.text(30, max_error, 'Max Temp. Diff.: %.2f °C' % max_diff,\n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        color='r', fontsize=22)\n",
    "    plt.xticks(x, ['0h'] + ['+%sh' % i for i in x[1:]])\n",
    "    plt.xlabel('Lead Time')\n",
    "    # plt.ylim((min_error,max_error))\n",
    "    plt.ylabel('Error [°C]')\n",
    "    plt.suptitle('%s - Error by Lead Time' % station_name_dict[station], fontsize=22)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    fig.savefig(plot_output_path + '/error_by_lead_time/Station_%s.png' % station)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot mean absolute error by lead time\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "station_name_dict = get_station_dict()\n",
    "\n",
    "error_data_array = xr.open_dataarray(error_data_path)\n",
    "num_stations, num_predictions, num_future_predictions = error_data_array.shape\n",
    "error_data = error_data_array.data\n",
    "\n",
    "x = range(0,num_future_predictions)\n",
    "initialization_times = range(0,24,3)\n",
    "\n",
    "# calculate the error per station and lead, and the overall min and max to scale the plots\n",
    "min_error, max_error = np.inf, -np.inf\n",
    "error = np.zeros((num_stations, num_future_predictions))\n",
    "for station in range(num_stations):\n",
    "    for lead in range(num_future_predictions):\n",
    "        error[station, lead] = np.mean([abs(e) for e in error_data[station,:,lead].flatten() if np.abs(e) < 1e10])\n",
    "        min_error = np.minimum(min_error, error[station, lead])\n",
    "        max_error = np.maximum(max_error, error[station, lead])\n",
    "\n",
    "# plot the data\n",
    "for station in range(num_stations):\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.plot(x, error[station])\n",
    "    max_diff = np.max(error[station]) - np.min(error[station])\n",
    "    plt.text(30, max_error, 'Max Temp. Diff.: %.2f °C' % max_diff,\n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        color='r', fontsize=22)\n",
    "    plt.xticks(x, ['0h'] + ['+%sh' % i for i in x[1:]])\n",
    "    plt.xlabel('Lead Time')\n",
    "    plt.ylim((min_error,max_error))\n",
    "    plt.ylabel('Error [°C]')\n",
    "    plt.suptitle('%s - Absolute Error by Lead Time' % station_name_dict[station], fontsize=22)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    fig.savefig(plot_output_path + '/absolute_error_by_lead_time/Station_%s.png' % station)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Error over Initialization Times (averaged over all Lead Times) plotted per Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot mean error by initialization time\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "station_name_dict = get_station_dict()\n",
    "\n",
    "error_data = np.load(error_data_path)\n",
    "num_stations, num_future_predictions, num_predictions = error_data.shape\n",
    "\n",
    "initialization_times = range(0,24,3)\n",
    "num_initialization_times = len(initialization_times)\n",
    "\n",
    "# calculate the error per station and initialization time, and the overall min and max to scale the plots\n",
    "min_error, max_error = np.inf, -np.inf\n",
    "error = np.zeros((num_stations, num_initialization_times))\n",
    "for station in range(num_stations):\n",
    "    for idx, init_time in enumerate(initialization_times):\n",
    "        error[station, idx] += np.mean([e for e in error_data[station,:24,idx::8].flatten() if np.abs(e) < 1e10])\n",
    "        min_error = np.minimum(min_error, error[station, idx])\n",
    "        max_error = np.maximum(max_error, error[station, idx])\n",
    "\n",
    "# plot error per station by initialization time\n",
    "for station in range(num_stations):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.plot(initialization_times, error[station])\n",
    "    max_diff = np.max(error[station]) - np.min(error[station])\n",
    "    plt.text(20, np.max(error[station]), 'Max Temp. Diff.: %.2f °C' % max_diff,\n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        color='r', fontsize=22)\n",
    "    #plt.ylim((min_error,max_error))\n",
    "    plt.ylabel('Error [°C]')\n",
    "    plt.xlabel('Initialization Time')\n",
    "    plt.suptitle('%s - Error by Initialization Time for next 24h' % station_name_dict[station], fontsize=22)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    fig.savefig(plot_output_path + '/error_by_init_time/Station_%s.png' % station)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot mean absolute error by initialization time\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "station_name_dict = get_station_dict()\n",
    "\n",
    "error_data = np.load(error_data_path)\n",
    "num_stations, num_future_predictions, num_predictions = error_data.shape\n",
    "\n",
    "initialization_times = range(0,24,3)\n",
    "\n",
    "# calculate the error per station and initialization time, and the overall min and max to scale the plots\n",
    "min_error, max_error = np.inf, -np.inf\n",
    "error = np.zeros((num_stations, num_initialization_times))\n",
    "for station in range(num_stations):\n",
    "    for idx, init_time in enumerate(initialization_times):\n",
    "        error[station, idx] += np.mean([abs(e) for e in error_data[station,:24,idx::8].flatten() if np.abs(e) < 1e10])\n",
    "        min_error = np.minimum(min_error, error[station, idx])\n",
    "        max_error = np.maximum(max_error, error[station, idx])\n",
    "\n",
    "# plot error per station by initialization time\n",
    "for station in range(num_stations):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.plot(initialization_times, error[station])\n",
    "    max_diff = np.max(error[station]) - np.min(error[station])\n",
    "    plt.text(20, np.max(error[station]), 'Max Temp. Diff.: %.2f °C' % max_diff,\n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        color='r', fontsize=22)\n",
    "    #plt.ylim((min_error,max_error))\n",
    "    plt.ylabel('Error [°C]')\n",
    "    plt.xlabel('Initialization Time')\n",
    "    plt.suptitle('%s - Absolute Error by Initialization Time for next 24h' % station_name_dict[station], fontsize=22)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    fig.savefig(plot_output_path + '/absolute_error_by_init_time/Station_%s.png' % station)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Error over Lead Times (averaged over all Init. Times & Stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot mean error over lead times for all stations combined\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "error_data = np.load(error_data_path)\n",
    "num_stations, num_future_predictions, num_predictions = error_data.shape\n",
    "\n",
    "error_data = np.swapaxes(error_data, 1, 0)\n",
    "\n",
    "future_predictions = range(num_future_predictions)\n",
    "mean_error_per_lead = np.zeros(num_future_predictions)\n",
    "for lead in future_predictions:\n",
    "    mean_error_per_lead[lead] = np.mean([e for e in error_data[lead].flatten() if np.abs(e) < 1e10])\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(np.array(future_predictions).reshape(-1,1), np.array(mean_error_per_lead))\n",
    "\n",
    "# plot data and trend line\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "real_data = plt.plot(future_predictions, mean_error_per_lead, 'b')\n",
    "reg_data = plt.plot(future_predictions, regr.predict(np.array(future_predictions).reshape(-1,1)), 'r--', alpha=0.5)\n",
    "\n",
    "# add text label of absolute error difference between min and max\n",
    "max_diff = np.max(mean_error_per_lead) - np.min(mean_error_per_lead)\n",
    "plt.text(3, np.max(mean_error_per_lead), 'Max Temp. Diff.: %.2f °C' % max_diff,\n",
    "    verticalalignment='top', horizontalalignment='left',\n",
    "    color='r', fontsize=22)\n",
    "\n",
    "# plot cosmetics\n",
    "plt.xticks(future_predictions, ['0h'] + ['+%sh' % i for i in future_predictions[1:]])\n",
    "plt.xlabel('Lead Time')\n",
    "plt.ylabel('Error [K]')\n",
    "plt.title('Mean Temperature Error over all Stations for Lead Times')\n",
    "plt.grid('On')\n",
    "fig.savefig(plot_output_path + '/nearest_grid_prediction_error_all_stations_over_lead_times.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot mean absolute error over lead times for all stations combined\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "error_data = np.load(error_data_path)\n",
    "num_stations, num_future_predictions, num_predictions = error_data.shape\n",
    "\n",
    "error_data = np.swapaxes(error_data, 1, 0)\n",
    "\n",
    "future_predictions = range(num_future_predictions)\n",
    "mean_error_per_lead = np.zeros(num_future_predictions)\n",
    "for lead in future_predictions:\n",
    "    mean_error_per_lead[lead] = np.mean([abs(e) for e in error_data[lead].flatten() if np.abs(e) < 1e10])\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(np.array(future_predictions).reshape(-1,1), np.array(mean_error_per_lead))\n",
    "\n",
    "# plot data and trend line\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "real_data = plt.plot(future_predictions, mean_error_per_lead, 'b')\n",
    "reg_data = plt.plot(future_predictions, regr.predict(np.array(future_predictions).reshape(-1,1)), 'r--', alpha=0.5)\n",
    "\n",
    "# add text label of absolute error difference between min and max\n",
    "max_diff = np.max(mean_error_per_lead) - np.min(mean_error_per_lead)\n",
    "plt.text(3, np.max(mean_error_per_lead), 'Max Temp. Diff.: %.2f °C' % max_diff,\n",
    "    verticalalignment='top', horizontalalignment='left',\n",
    "    color='r', fontsize=22)\n",
    "\n",
    "# plot cosmetics\n",
    "plt.xticks(future_predictions, ['0h'] + ['+%sh' % i for i in future_predictions[1:]])\n",
    "plt.xlabel('Lead Time')\n",
    "plt.ylabel('Error [K]')\n",
    "plt.title('Mean absolute Temperature Error over all Stations for Lead Times')\n",
    "plt.grid('On')\n",
    "fig.savefig(plot_output_path + '/nearest_grid_absolute_prediction_error_all_stations_over_lead_times.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "## Periodogram of Error over complete Measurement Period plottet for each Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot periodogram of error per station\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# stations with heavy diurnal variantions\n",
    "diurnal_stations = []\n",
    "\n",
    "error_data = np.load(error_data_path)\n",
    "n_stations, _, data_length = error_data.shape\n",
    "sample_rate = 8\n",
    "station_name_dict = get_station_dict()\n",
    "for i in range(144):\n",
    "    fig, axes = plt.subplots(1, figsize=(20, 10))\n",
    "    f, Pxx_den = signal.periodogram(error_data[i,0,:], sample_rate)\n",
    "    relevant_frequencies = [idx for idx, y in enumerate(Pxx_den) if y > 500]\n",
    "    if len(relevant_frequencies) > 0 and len(relevant_frequencies) < 10:\n",
    "        diurnal_stations += [(i, station_name_dict[i])]\n",
    "        print('Station %s\\t%s' % (i, station_name_dict[i]))\n",
    "    axes.plot(f, Pxx_den)\n",
    "    axes.set_xlabel('Frequency [1/day]')\n",
    "    plt.suptitle(station_name_dict[i] + ' (Station %s)' % str(i+1))\n",
    "    fig.savefig(plot_output_path + '/periodogram/error_periodogram_station_%s' % str(i))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Error per Station plottet on geographic Map, Location of corrupted Stations, Error vs. Height Scatter Plot (with xarray and TOPOdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot station by error on map\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# load time invariant data per station, e.g. station attributes itself, and attributes of surrounding grid points\n",
    "f = open(time_invariant_data_per_station_path, \"rb\")\n",
    "time_invariant_data_per_station = pkl.load(f)\n",
    "f.close()\n",
    "# time invariant observation data\n",
    "OBS_inv = nc.Dataset(data_path + \"/c1ffsurf000_timeinvariant_lonlat.nc\")\n",
    "# load baseline error data\n",
    "error_data = np.load(error_data_path).squeeze()\n",
    "# dictionary with index of station in [0,143] to index of station in filtered data array [0,<=143]\n",
    "idx_station_dict = {}\n",
    "# filter out stations with corrupted measurements\n",
    "filtered_error_data = None\n",
    "stations_with_errors = []\n",
    "for i in range(error_data.shape[0]):\n",
    "    if np.max(error_data[i]) > 1e10:\n",
    "        stations_with_errors += [i]\n",
    "        continue\n",
    "    if filtered_error_data is None:\n",
    "        filtered_error_data = error_data[i]\n",
    "        idx_station_dict[0] = i\n",
    "    else:\n",
    "        filtered_error_data = np.vstack((filtered_error_data, error_data[i]))\n",
    "        idx_station_dict[len(filtered_error_data)-1] = i\n",
    "\n",
    "# time invarioant (x,y,z)-coordiantes of stations\n",
    "station_x = [OBS_inv['rlon'][time_invariant_data_per_station[idx_station_dict[i]]['self']['closest_grid_point'][1]] for i in range(len(filtered_error_data))]\n",
    "station_y = [OBS_inv['rlat'][time_invariant_data_per_station[idx_station_dict[i]]['self']['closest_grid_point'][0]] for i in range(len(filtered_error_data))]\n",
    "station_z = [time_invariant_data_per_station[idx_station_dict[i]]['self']['height'] for i in range(len(filtered_error_data))]\n",
    "\n",
    "error_station_x = [OBS_inv['rlon'][time_invariant_data_per_station[stations_with_errors[i]]['self']['closest_grid_point'][1]] for i in range(len(stations_with_errors))]\n",
    "error_station_y = [OBS_inv['rlat'][time_invariant_data_per_station[stations_with_errors[i]]['self']['closest_grid_point'][0]] for i in range(len(stations_with_errors))]\n",
    "\n",
    "rlat_min, rlat_max, rlon_min, rlon_max = -1.3, 1, -3, 0.5\n",
    "\n",
    "# plot the absolute error of each station in a heat map\n",
    "fig = plt.figure(figsize=(26,15))\n",
    "ax = fig.add_subplot(111)\n",
    "plot_map(ax, rlat_min, rlat_max, rlon_min, rlon_max)\n",
    "cax = ax.scatter(station_x, station_y, c=np.mean(np.abs(filtered_error_data),1), s=200,\n",
    "                 cmap='YlOrBr', norm=mpl.colors.Normalize(vmin=0, vmax=3))\n",
    "cbar = plt.colorbar(cax, format=ticker.FuncFormatter(lambda x, pos: \"%.1f °C\" % x))\n",
    "ax.set_title('Error of stations', fontsize=22)\n",
    "ax.grid('off')\n",
    "plt.axis('scaled')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "fig.savefig(plot_output_path + '/absolute_station_error_on_map.png')\n",
    "plt.close()\n",
    "\n",
    "# plot the error of each station in a heat map\n",
    "fig = plt.figure(figsize=(26,15))\n",
    "ax = fig.add_subplot(111)\n",
    "plot_map(ax, rlat_min, rlat_max, rlon_min, rlon_max)\n",
    "cax = ax.scatter(station_x, station_y, c=np.mean(filtered_error_data,1), s=200,\n",
    "                 cmap='bwr', norm=mpl.colors.Normalize(vmin=-3, vmax=3))\n",
    "cbar = plt.colorbar(cax, format=ticker.FuncFormatter(lambda x, pos: \"%.1f °C\" % x))\n",
    "ax.set_title('Error of stations', fontsize=22)\n",
    "ax.grid('off')\n",
    "plt.axis('scaled')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "fig.savefig(plot_output_path + '/station_error_on_map.png')\n",
    "plt.close()\n",
    "\n",
    "# Stations with measurment error\n",
    "fig = plt.figure(figsize=(26,15))\n",
    "ax = fig.add_subplot(111)\n",
    "plot_map(ax, rlat_min, rlat_max, rlon_min, rlon_max)\n",
    "ax.scatter(error_station_x, error_station_y, s=200, color='r')\n",
    "ax.set_title('Stations with Errors in Measurement Sequence', fontsize=22)\n",
    "ax.grid('off')\n",
    "plt.axis('scaled')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "fig.savefig(plot_output_path + '/corrupted_stations.png')\n",
    "plt.close()\n",
    "            \n",
    "# Station absolute Error vs. Station Height Scatter plot\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "x,y = list(zip(*sorted(zip(np.mean(np.abs(filtered_error_data),1), station_z))))\n",
    "plt.scatter(x,y)\n",
    "\n",
    "\n",
    "# calc the trendline\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "# plot trend line\n",
    "plt.plot(x,p(x),\"r--\")\n",
    "\n",
    "plt.xlabel('Error [°C]')\n",
    "plt.ylabel('Height (normalized)')\n",
    "plt.suptitle('Absolute Error vs. Station Height Plot')\n",
    "fig.savefig(plot_output_path + '/absolute_station_error_agains_height.png')\n",
    "plt.close()\n",
    "\n",
    "# Station Error vs. Station Height Scatter plot\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "x,y = list(zip(*sorted(zip(np.mean(filtered_error_data,1), station_z))))\n",
    "plt.scatter(x,y)\n",
    "\n",
    "# calc the trendline\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "# plot trend line\n",
    "plt.plot(x,p(x),\"r--\")\n",
    "\n",
    "plt.xlabel('Error [°C]')\n",
    "plt.ylabel('Height (normalized)')\n",
    "plt.suptitle('Error vs. Station Height Plot')\n",
    "fig.savefig(plot_output_path + '/station_error_agains_height.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Map Plots without error data with \"BaseMap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc_file = NetCDFFile(data_path + \"/c1ffsurf000_timeinvariant_lonlat.nc\")\n",
    "\n",
    "lat = nc_file.variables['lat'][:]\n",
    "lon = nc_file.variables['lon'][:]\n",
    "HH = nc_file.variables['HH'][:]\n",
    "FR_LAND = nc_file.variables['FR_LAND'][:]\n",
    "SOILTYP = nc_file.variables['SOILTYP'][:]\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "map=Basemap(projection=\"lcc\",resolution=\"f\",width=4E5,height=2.5E5,\n",
    "                             lon_0=8.17,lat_0=46.8,fix_aspect=False)\n",
    "map.drawcountries(zorder=1,color=\"black\", linewidth=1)\n",
    "map.shadedrelief(scale=2.5)\n",
    "map.drawcoastlines(color=\"black\",linewidth=1.2)\n",
    "map.drawrivers(linewidth=0.5,color=\"blue\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc = NetCDFFile(data_path + \"/c1ffsurf000_timeinvariant_lonlat.nc\")\n",
    "\n",
    "lat = nc.variables['lat'][:]\n",
    "lon = nc.variables['lon'][:]\n",
    "HH = nc.variables['HH'][:]\n",
    "FR_LAND = nc.variables['FR_LAND'][:]\n",
    "SOILTYP = nc.variables['SOILTYP'][:]\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "m = Basemap(llcrnrlon=5.8,llcrnrlat=45.8,urcrnrlon=11.,urcrnrlat=47.9, epsg=5520)\n",
    "m.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 3000, verbose= True)\n",
    "m.drawcountries(zorder=1,color=\"black\", linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Error per Hour plottet (averaged over all Stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Error plot per hour\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "hour_error_dict = {\n",
    "    0 : [],\n",
    "    3 : [],\n",
    "    6 : [],\n",
    "    9 : [],\n",
    "    12 : [],\n",
    "    15 : [],\n",
    "    18 : [],\n",
    "    21 : []\n",
    "}\n",
    "\n",
    "error_data = np.load(error_data_path).squeeze()\n",
    "error_mask = np.where(error_data < 1e10)\n",
    "\n",
    "hours = np.array([[(i*3) % 24 for i in range(error_data.shape[1])] for j in range(error_data.shape[0])])\n",
    "filtered_error_hour = np.dstack((error_data, hours))[error_mask]\n",
    "\n",
    "for idx, d in enumerate(filtered_error_hour):\n",
    "    hour_error_dict[d[1]] += [d[0]]\n",
    "    \n",
    "num_hours = len(hour_error_dict.keys())\n",
    "mean = np.zeros(num_hours)\n",
    "std = np.zeros(num_hours)\n",
    "for idx, key in enumerate(hour_error_dict.keys()):\n",
    "    mean[idx] = np.mean(hour_error_dict[key])\n",
    "    std[idx] = np.std(hour_error_dict[key])\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.errorbar(hour_error_dict.keys(), mean, std)\n",
    "plt.xlabel('Hour [h]')\n",
    "plt.ylabel('Error [°C]')\n",
    "plt.suptitle('Error agains Hour')\n",
    "fig.savefig(plot_output_path + '/all_stations_error_against_hour.png')\n",
    "plt.close()\n",
    "\n",
    "mean = np.zeros(num_hours)\n",
    "std = np.zeros(num_hours)\n",
    "for idx, key in enumerate(hour_error_dict.keys()):\n",
    "    mean[idx] = np.mean(np.abs(hour_error_dict[key]))\n",
    "    std[idx] = np.std(np.abs(hour_error_dict[key]))\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.errorbar(hour_error_dict.keys(), mean, std)\n",
    "plt.xlabel('Hour [h]')\n",
    "plt.ylabel('Error [°C]')\n",
    "plt.suptitle('Absolute Error agains Hour')\n",
    "fig.savefig(plot_output_path + '/all_stations_absolute_error_against_hour.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Error per Hour plotted for each Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Error plot per hour per station\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "error_data = np.load(error_data_path).squeeze()[:,1,:]\n",
    "hours = np.array([(i*3) % 24 for i in range(error_data.shape[1])])\n",
    "\n",
    "station_name_dict = get_station_dict()\n",
    "\n",
    "# mean error for each station per hour\n",
    "station_mean_error = np.zeros((144,8))\n",
    "\n",
    "for station in range(144):\n",
    "    hour_error_dict = {\n",
    "        0 : [],\n",
    "        3 : [],\n",
    "        6 : [],\n",
    "        9 : [],\n",
    "        12 : [],\n",
    "        15 : [],\n",
    "        18 : [],\n",
    "        21 : []\n",
    "    }\n",
    "    \n",
    "    error_mask = np.where(error_data[station,:] < 1e10)\n",
    "    filtered_error_hour = np.dstack((error_data[station,:], hours)).squeeze()[error_mask]\n",
    "\n",
    "    for idx, d in enumerate(filtered_error_hour):\n",
    "        hour_error_dict[d[1]] += [d[0]]\n",
    "\n",
    "    num_hours = len(hour_error_dict.keys())\n",
    "    mean = np.zeros(num_hours)\n",
    "    std = np.zeros(num_hours)\n",
    "    for idx, key in enumerate(hour_error_dict.keys()):\n",
    "        mean[idx] = np.mean(hour_error_dict[key])\n",
    "        std[idx] = np.std(hour_error_dict[key])\n",
    "    \n",
    "    # could be reused for bias corrigated base line error\n",
    "    station_mean_error[station] = mean\n",
    "\n",
    "max_error, min_error = np.max(station_mean_error), np.min(station_mean_error)\n",
    "\n",
    "for station in range(144):\n",
    "    fig = plt.figure(figsize=(14,8))\n",
    "    plt.plot(hour_error_dict.keys(), station_mean_error[station])\n",
    "    \n",
    "    max_difference = np.max(station_mean_error[station]) - np.min(station_mean_error[station])\n",
    "    plt.annotate('Max Temp. Diff.: %.2f °C' % max_difference,\n",
    "           xy=(1, 1.01), horizontalalignment='right', verticalalignment='bottom', color='red',\n",
    "         xycoords=\"axes fraction\", fontsize=16)\n",
    "    \n",
    "    plt.ylim((min_error, max_error))\n",
    "    plt.xlabel('Hour [h]')\n",
    "    plt.ylabel('Error [°C]')\n",
    "    plt.title('%s - Error agains Hour' % station_name_dict[station], fontsize=22)\n",
    "    plt.grid('On')\n",
    "    fig.savefig(plot_output_path_no_lead_times + '/error_per_hour/error_against_hour_station_%s.png' % str(station))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "## Error over complete Measurement Period plotted by Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot error per station over years, if invalid errors are excluded\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "error_data = np.load(error_data_path)\n",
    "n_stations, _, data_length = error_data.shape\n",
    "year_length=365*8\n",
    "x_times = get_time_axis(data_length,year_length)\n",
    "station_name_dict = get_station_dict()\n",
    "# loop over stations\n",
    "for station in range(n_stations):\n",
    "    data = [error_data[station,0,i:i + year_length] for i in range(0, data_length, year_length)]\n",
    "    fig, axes = plt.subplots(len(data), figsize=(20, 20))\n",
    "    min_y = np.min([e for e in error_data[station,0,:].flatten() if e < 1e10])\n",
    "    max_y = np.max([e for e in error_data[station,0,:].flatten() if e < 1e10])\n",
    "    for i in range(len(data)):\n",
    "        # get start/end of the yearly periods\n",
    "        start = x_times[i][0]\n",
    "        end = x_times[i][0] + timedelta(days=365)\n",
    "        # get the data and corresponding datetimes without the faulty samples\n",
    "        x,error_filtered_data = get_filtered_data(x_times[i], data[i])\n",
    "        # plot\n",
    "        axes[i].plot(x, error_filtered_data, color='b', alpha=0.2)\n",
    "        try:\n",
    "        # get filtered line to show trend\n",
    "            b, a = signal.butter(3, 0.015)\n",
    "            y = signal.filtfilt(b, a, error_filtered_data)\n",
    "            axes[i].plot(x, y ,color='r')\n",
    "        except ValueError:\n",
    "            continue\n",
    "        # set x-/y-limits\n",
    "        axes[i].set_xlim((start,end))\n",
    "        axes[i].set_ylim((min_y,max_y))\n",
    "\n",
    "    axes[len(data)-1].set_xlabel('Days')\n",
    "    plt.suptitle('%s (Station %s)' % (station_name_dict[station],station))\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(plot_output_path + '/seasonal_error/seasonal_error_station_%s' % str(station))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot error per station over years with savitzky_golay smoothing, if invalid errors are excluded\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
    "    The Savitzky-Golay filter removes high frequency noise from data.\n",
    "    It has the advantage of preserving the original shape and\n",
    "    features of the signal better than other types of filtering\n",
    "    approaches, such as moving averages techniques.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like, shape (N,)\n",
    "        the values of the time history of the signal.\n",
    "    window_size : int\n",
    "        the length of the window. Must be an odd integer number.\n",
    "    order : int\n",
    "        the order of the polynomial used in the filtering.\n",
    "        Must be less then `window_size` - 1.\n",
    "    deriv: int\n",
    "        the order of the derivative to compute (default = 0 means only smoothing)\n",
    "    Returns\n",
    "    -------\n",
    "    ys : ndarray, shape (N)\n",
    "        the smoothed signal (or it's n-th derivative).\n",
    "    Notes\n",
    "    -----\n",
    "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
    "    suited for smoothing noisy data. The main idea behind this\n",
    "    approach is to make for each point a least-square fit with a\n",
    "    polynomial of high order over a odd-sized window centered at\n",
    "    the point.\n",
    "    Examples\n",
    "    --------\n",
    "    t = np.linspace(-4, 4, 500)\n",
    "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
    "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(t, y, label='Noisy signal')\n",
    "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
    "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
    "       Data by Simplified Least Squares Procedures. Analytical\n",
    "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
    "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
    "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
    "       Cambridge University Press ISBN-13: 9780521880688\n",
    "    \"\"\"\n",
    "    from math import factorial\n",
    "    \n",
    "    try:\n",
    "        window_size = np.abs(np.int(window_size))\n",
    "        order = np.abs(np.int(order))\n",
    "    except (ValueError, msg):\n",
    "        raise ValueError(\"window_size and order have to be of type int\")\n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"window_size size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "    order_range = range(order+1)\n",
    "    half_window = (window_size -1) // 2\n",
    "    # precompute coefficients\n",
    "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "    # pad the signal at the extremes with\n",
    "    # values taken from the signal itself\n",
    "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, y, lastvals))\n",
    "    return np.convolve( m[::-1], y, mode='valid')\n",
    "\n",
    "error_data = np.load(error_data_path)\n",
    "n_stations, _, data_length = error_data.shape\n",
    "year_length=365*8\n",
    "x_times = get_time_axis(data_length,year_length)\n",
    "station_name_dict = get_station_dict()\n",
    "# loop over stations\n",
    "for station in range(n_stations):\n",
    "    data = [error_data[station,0,i:i + year_length] for i in range(0, data_length, year_length)]\n",
    "    fig, axes = plt.subplots(len(data), figsize=(20, 20))\n",
    "    min_y = np.min([e for e in error_data[station,0,:].flatten() if e < 1e10])\n",
    "    max_y = np.max([e for e in error_data[station,0,:].flatten() if e < 1e10])\n",
    "    for i in range(len(data)):\n",
    "        # get start/end of the yearly periods\n",
    "        start = x_times[i][0]\n",
    "        end = x_times[i][0] + timedelta(days=365)\n",
    "        # get the data and corresponding datetimes without the faulty samples\n",
    "        x,error_filtered_data = get_filtered_data(x_times[i], data[i])\n",
    "        # plot\n",
    "        axes[i].plot(x, error_filtered_data, color='b', alpha=0.2)\n",
    "        try:\n",
    "        # get filtered line to show trend\n",
    "            y = savitzky_golay(error_filtered_data, 87, 1, 0)\n",
    "            axes[i].plot(x, y ,color='r')\n",
    "        except ValueError:\n",
    "            continue\n",
    "        # set x-/y-limits\n",
    "        axes[i].set_xlim((start,end))\n",
    "        axes[i].set_ylim((min_y,max_y))\n",
    "\n",
    "    axes[len(data)-1].set_xlabel('Days')\n",
    "    plt.suptitle('%s (Station %s)' % (station_name_dict[station],station))\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(plot_output_path + '/seasonal_error/savitzky_golay_seasonal_error_station_%s' % str(station))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot error per station over complete time series, if invalid errors are excluded\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "error_data = np.load(error_data_path)\n",
    "n_stations, _, data_length = error_data.shape\n",
    "x_times = get_time_axis(data_length)\n",
    "station_name_dict = get_station_dict()\n",
    "# loop over stations\n",
    "for station in range(n_stations):\n",
    "    data = error_data[station,0,:]\n",
    "    fig, axes = plt.subplots(1, figsize=(30, 10))\n",
    "    min_y = np.min([e for e in error_data[station,0,:].flatten() if e < 1e10])\n",
    "    max_y = np.max([e for e in error_data[station,0,:].flatten() if e < 1e10])\n",
    "    # get start/end of the yearly periods\n",
    "    start = x_times[0]\n",
    "    end = x_times[-1]\n",
    "    # get the data and corresponding datetimes without the faulty samples\n",
    "    x,error_filtered_data = get_filtered_data(x_times, data)\n",
    "    # plot\n",
    "    axes.plot(x, error_filtered_data, color='b', alpha=0.2)\n",
    "    try:\n",
    "    # get filtered line to show trend\n",
    "        b, a = signal.butter(3, 0.015)\n",
    "        y = signal.filtfilt(b, a, error_filtered_data)\n",
    "        axes.plot(x, y ,color='r')\n",
    "    except ValueError:\n",
    "        continue\n",
    "    # set x-/y-limits\n",
    "    axes.set_xlim((start,end))\n",
    "    axes.set_ylim((min_y,max_y))\n",
    "\n",
    "    axes.set_xlabel('Days')\n",
    "    plt.suptitle('%s (Station %s)' % (station_name_dict[station],station))\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(plot_output_path + '/seasonal_error/error_station_%s' % str(station))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot absolute error per station over years, if invalid errors are excluded\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "error_data = np.abs(np.load(error_data_path))\n",
    "n_stations, _, data_length = error_data.shape\n",
    "year_length=365*8\n",
    "x_times = get_time_axis(data_length,year_length)\n",
    "station_name_dict = get_station_dict()\n",
    "# loop over stations\n",
    "for station in range(n_stations):\n",
    "    data = [error_data[station,0,i:i + year_length] for i in range(0, data_length, year_length)]\n",
    "    fig, axes = plt.subplots(len(data), figsize=(20, 20))\n",
    "    max_y = np.max([e for e in error_data[station,0,:].flatten() if e < 1e10])\n",
    "    for i in range(len(data)):\n",
    "        # get start/end of the yearly periods\n",
    "        start = x_times[i][0]\n",
    "        end = x_times[i][0] + timedelta(days=365)\n",
    "        # get the data and corresponding datetimes without the faulty samples\n",
    "        x,error_filtered_data = get_filtered_data(x_times[i], data[i])\n",
    "        error_filtered_data = error_filtered_data\n",
    "        # plot\n",
    "        axes[i].plot(x, error_filtered_data, color='b', alpha=0.2)\n",
    "        try:\n",
    "        # get filtered line to show trend\n",
    "            b, a = signal.butter(3, 0.015)\n",
    "            y = signal.filtfilt(b, a, error_filtered_data)\n",
    "            axes[i].plot(x, y ,color='r')\n",
    "        except ValueError:\n",
    "            continue\n",
    "        # set x-/y-limits\n",
    "        axes[i].set_xlim((start,end))\n",
    "        axes[i].set_ylim((0,max_y))\n",
    "\n",
    "    axes[len(data)-1].set_xlabel('Days')\n",
    "    plt.suptitle('%s (Station %s)' % (station_name_dict[station],station))\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    fig.savefig(plot_output_path + '/seasonal_error/absolute_seasonal_error_station_%s' % str(station))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Plot absolute error per station over complete time series, if invalid errors are excluded\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "error_data = np.abs(np.load(error_data_path))\n",
    "n_stations, _, data_length = error_data.shape\n",
    "x_times = get_time_axis(data_length)\n",
    "station_name_dict = get_station_dict()\n",
    "# loop over stations\n",
    "for station in range(n_stations):\n",
    "    data = error_data[station,0,:]\n",
    "    fig, axes = plt.subplots(1, figsize=(30, 10))\n",
    "    min_y = np.min([e for e in error_data[station,0,:].flatten() if e < 1e10])\n",
    "    max_y = np.max([e for e in error_data[station,0,:].flatten() if e < 1e10])\n",
    "    # get start/end of the yearly periods\n",
    "    start = x_times[0]\n",
    "    end = x_times[-1]\n",
    "    # get the data and corresponding datetimes without the faulty samples\n",
    "    x,error_filtered_data = get_filtered_data(x_times, data)\n",
    "    # plot\n",
    "    axes.plot(x, error_filtered_data, color='b', alpha=0.2)\n",
    "    try:\n",
    "    # get filtered line to show trend\n",
    "        b, a = signal.butter(3, 0.015)\n",
    "        y = signal.filtfilt(b, a, error_filtered_data)\n",
    "        axes.plot(x, y ,color='r')\n",
    "    except ValueError:\n",
    "        continue\n",
    "    # set x-/y-limits\n",
    "    axes.set_xlim((start,end))\n",
    "    axes.set_ylim((0,max_y))\n",
    "\n",
    "    axes.set_xlabel('Days')\n",
    "    plt.suptitle('%s (Station %s)' % (station_name_dict[station],station))\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(plot_output_path + '/seasonal_error/absolute_error_station_%s' % str(station))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Stations by Error plottet on geographic Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Cluster stations by error\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "error_data = np.load(error_data_path).squeeze()\n",
    "K=2\n",
    "station_name_dict = get_station_dict()\n",
    "\n",
    "idx_station_dict = {}\n",
    "\n",
    "filtered_error_data = None\n",
    "for i in range(error_data.shape[0]):\n",
    "    if np.max(error_data[i]) > 1e10:\n",
    "        continue\n",
    "    if filtered_error_data is None:\n",
    "        filtered_error_data = error_data[i]\n",
    "        idx_station_dict[0] = i\n",
    "    else:\n",
    "        filtered_error_data = np.vstack((filtered_error_data, error_data[i]))\n",
    "        idx_station_dict[len(filtered_error_data)-1] = i\n",
    "\n",
    "OBS = nc.Dataset(observations)\n",
    "station_x, station_y = OBS['lon'][:], OBS['lat'][:]\n",
    "\n",
    "color_map = get_cmap(10)\n",
    "\n",
    "# KMean\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "clusteded_stations = KMeans(n_clusters=K).fit_predict(filtered_error_data)\n",
    "colors = ([color_map(k*2) for _, k in enumerate(clusteded_stations)])\n",
    "pylab.scatter(station_x,station_y, c=colors)\n",
    "fig.savefig(plot_output_path + '/cluster_stations_by_error_k_means.png')\n",
    "plt.close()\n",
    "\n",
    "# Spectral\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "clusteded_stations = SpectralClustering(n_clusters=K).fit_predict(filtered_error_data)\n",
    "colors = ([color_map(k*2) for _, k in enumerate(clusteded_stations)])\n",
    "pylab.scatter(station_x,station_y, c=colors)\n",
    "fig.savefig(plot_output_path + '/cluster_stations_by_error_spectral.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}